{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: train a MNIST digit classifier CNN using only Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf # tensorflow is only for downloading the data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "val_samples = 1000\n",
    "(x_train, x_val), (y_train, y_val) = (x_train[:-1000], x_train[-1000:]), (y_train[:-1000], y_train[-1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv Layer 0:\n",
      "  -  Input shape:(28, 28, 1)\n",
      "  -  Output shape:(13, 13, 32)\n",
      "Conv Layer 1:\n",
      "  -  Input shape:(13, 13, 32)\n",
      "  -  Output shape:(6, 6, 64)\n",
      "Dense Layer 0:\n",
      "  -  Input shape:2304\n",
      "  -  Output shape:128\n",
      "Dense Layer 1:\n",
      "  -  Input shape:128\n",
      "  -  Output shape:10\n"
     ]
    }
   ],
   "source": [
    "model = dict()\n",
    "\n",
    "\n",
    "categories = 10\n",
    "\n",
    "\n",
    "# convolutional parameters \n",
    "\n",
    "filter_sizes = [[3,3,1], [3,3,32]]\n",
    "filter_number = [32,64]\n",
    "step = [2,2]\n",
    "image_size = (28,28,1)\n",
    "\n",
    "# dense parameters\n",
    "\n",
    "number_of_dense_layers = 2\n",
    "output_nodes = [128,10]\n",
    "activations = ['relu', 'softmax']\n",
    "\n",
    "\n",
    "current_input_size = image_size\n",
    "\n",
    "for cnn_layer in range(len(filter_number)):\n",
    "    \n",
    "    d0 = filter_sizes[cnn_layer][0]\n",
    "    d1 = filter_sizes[cnn_layer][1]\n",
    "    d2 = filter_sizes[cnn_layer][2]\n",
    "    d3 = filter_number[cnn_layer]\n",
    "    \n",
    "    model['F'+str(cnn_layer+1)] = np.random.randn(d0, d1, d2, d3) / np.sqrt(d0*d1*d2) # filter 1\n",
    "    \n",
    "    # calculate output shape\n",
    "    steps_i = (current_input_size[0]+1-2*(filter_sizes[cnn_layer][0]//2))//step[cnn_layer]\n",
    "    steps_j = (current_input_size[1]+1-2*(filter_sizes[cnn_layer][1]//2))//step[cnn_layer]\n",
    "    print('Conv Layer {}:'.format(cnn_layer))\n",
    "    print('  -  Input shape:{}'.format(current_input_size))\n",
    "    current_input_size = (steps_i,steps_j,filter_number[cnn_layer])\n",
    "    print('  -  Output shape:{}'.format(current_input_size))\n",
    "    \n",
    "    #Bias\n",
    "    model['b_conv_'+str(cnn_layer+1)] = np.random.randn(current_input_size[0], current_input_size[1],\n",
    "                                                   current_input_size[2]) / np.sqrt(current_input_size[2])\n",
    "    \n",
    "dense_input_size = np.prod(current_input_size)\n",
    "\n",
    "for dense_layer in range(number_of_dense_layers):\n",
    "    \n",
    "    model['D'+str(dense_layer+1)] = np.random.randn(output_nodes[dense_layer], dense_input_size) / np.sqrt(dense_input_size)# dense layer weights\n",
    "    model['b_dense_'+str(dense_layer+1)] = np.random.randn(output_nodes[dense_layer]) / np.sqrt(output_nodes[dense_layer])# dense layer weights\n",
    "    \n",
    "    print('Dense Layer {}:'.format(dense_layer))\n",
    "    print('  -  Input shape:{}'.format(dense_input_size))\n",
    "    print('  -  Output shape:{}'.format(output_nodes[dense_layer]))\n",
    "    \n",
    "    dense_input_size = output_nodes[dense_layer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(y):\n",
    "    return np.exp(y)/np.sum(np.exp(y))\n",
    "\n",
    "# Convolution\n",
    "def conv_forward(x,layer):\n",
    "    global model, filter_number, filter_sizes, step\n",
    "    \n",
    "    x = x.reshape((x.shape[0],x.shape[1],filter_sizes[layer][2],1))\n",
    "\n",
    "    x = np.tile(x,filter_number[layer])\n",
    "\n",
    "    steps_i = (x.shape[0]+1-2*(filter_sizes[layer][0]//2))//step[layer]\n",
    "    steps_j = (x.shape[1]+1-2*(filter_sizes[layer][1]//2))//step[layer]\n",
    "\n",
    "    y = np.zeros((steps_i,steps_j,filter_number[layer]))\n",
    "\n",
    "    \n",
    "    index_i = 0\n",
    "    \n",
    "    for i in range(filter_sizes[layer][0]//2, x.shape[0]- filter_sizes[layer][0]//2, step[layer]):\n",
    "        index_j = 0\n",
    "        for j in range(filter_sizes[layer][1]//2, x.shape[1]- filter_sizes[layer][1]//2, step[layer]):\n",
    "            local_x = x[i-filter_sizes[layer][0]//2: i+filter_sizes[layer][0]//2+1,j-filter_sizes[layer][1]//2:\n",
    "                        j+filter_sizes[layer][0]//2+1]\n",
    "            y[index_i][index_j] = np.sum(np.multiply(local_x, model['F'+str(layer+1)]).reshape(-1,filter_number[layer]), axis = 0)\n",
    "\n",
    "            index_j+= 1\n",
    "        index_i+= 1\n",
    "    # Add bias\n",
    "    y += model['b_conv_'+str(layer+1)]\n",
    "    # ReLU\n",
    "    y[y<0] = 0\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "# Dense\n",
    "def dense_forward(x, dense_layer):\n",
    "    global model, activations\n",
    "    \n",
    "    h = np.dot(model['D'+str(dense_layer+1)], x) + model['b_dense_'+str(dense_layer+1)]\n",
    "    \n",
    "    # activation\n",
    "    \n",
    "    if activations[dense_layer] == 'relu':\n",
    "        y = h\n",
    "        y[y<0] = 0.\n",
    "    \n",
    "    if activations[dense_layer] == 'softmax':\n",
    "        y = softmax(h)\n",
    "    \n",
    "    return y,h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backprop now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_ce_grad(h, y_true):\n",
    "    y_onehot = np.zeros_like(h)\n",
    "    y_onehot[y_true] = 1\n",
    "    grad = softmax(h)-y_onehot\n",
    "    return grad\n",
    "\n",
    "def backprop_dense(dy, h, dense_layer):\n",
    "    global model\n",
    "\n",
    "    # bias update\n",
    "    db = dy\n",
    "\n",
    "    # Weights update\n",
    "    dw = np.outer(dy, h)\n",
    "    \n",
    "    dh = np.dot(dy, model['D'+str(dense_layer + 1)])\n",
    "\n",
    "    return dw, db, dh\n",
    "\n",
    "def conv_backprop(x,dh,layer):\n",
    "    global model, filter_number, filter_sizes, step\n",
    "    \n",
    "    x = x.reshape((x.shape[0],x.shape[1],filter_sizes[layer][2],1))\n",
    "    dx = np.zeros_like(x)\n",
    "    x = np.tile(x,filter_number[layer])\n",
    "\n",
    "    steps_i = (x.shape[0]+1-2*(filter_sizes[layer][0]//2))//step[layer]\n",
    "    steps_j = (x.shape[1]+1-2*(filter_sizes[layer][1]//2))//step[layer]\n",
    "\n",
    "    y = np.zeros((steps_i,steps_j,filter_number[layer]))\n",
    "    \n",
    "    index_i = 0\n",
    "    \n",
    "    #Weights update\n",
    "    dw = np.zeros_like(model['F'+str(layer+1)])\n",
    "    db = dh\n",
    "    \n",
    "    for i in range(filter_sizes[layer][0]//2, x.shape[0]- filter_sizes[layer][0]//2, step[layer]):\n",
    "        index_j = 0\n",
    "        for j in range(filter_sizes[layer][1]//2, x.shape[1]- filter_sizes[layer][1]//2, step[layer]):\n",
    "            local_x = x[i-filter_sizes[layer][0]//2: i+filter_sizes[layer][0]//2+1,j-filter_sizes[layer][1]//2:\n",
    "                        j+filter_sizes[layer][0]//2+1]\n",
    "            local_dx = np.sum(np.multiply(model['F'+str(layer+1)], dh[index_i][index_j]), axis=-1)\n",
    "            dx[i-filter_sizes[layer][0]//2: i+filter_sizes[layer][0]//2+1,j-filter_sizes[layer][1]//2:\n",
    "                        j+filter_sizes[layer][0]//2+1,:,0] += local_dx\n",
    "            dw+=np.multiply(local_x, dh[index_i][index_j])\n",
    "            index_j+= 1\n",
    "        index_i+= 1\n",
    "    \n",
    "    dx = dx.reshape(dx.shape[:-1])\n",
    "    \n",
    "    return dw,db,dx\n",
    "\n",
    "import copy\n",
    "\n",
    "#initial = copy.deepcopy(model)\n",
    "\n",
    "def eval_model(x, y_true):\n",
    "    \n",
    "    h1 = conv_forward(x, 0)\n",
    "    h2 = conv_forward(h1, 1)\n",
    "    h2f = h2.flatten()\n",
    "    y3, h3 = dense_forward(h2f, 0)\n",
    "    y, h = dense_forward(y3, 1) \n",
    "    \n",
    "    return y, np.argmax(y) == y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data is 7.0%\n",
      "Validation Accuracy is 9.0%\n",
      "Validation Accuracy is 59.0%\n",
      "Validation Accuracy is 69.0%\n",
      "Validation Accuracy is 82.0%\n",
      "Validation Accuracy is 89.0%\n",
      "Validation Accuracy is 80.0%\n",
      "Validation Accuracy is 77.0%\n",
      "Validation Accuracy is 80.0%\n",
      "Validation Accuracy is 92.0%\n",
      "Validation Accuracy is 84.0%\n",
      "Accuracy on training data is 78.0%\n",
      "Validation Accuracy is 88.0%\n",
      "Validation Accuracy is 80.0%\n",
      "Validation Accuracy is 89.0%\n",
      "Validation Accuracy is 92.0%\n",
      "Validation Accuracy is 84.0%\n",
      "Validation Accuracy is 90.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 92.0%\n",
      "Validation Accuracy is 89.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Accuracy on training data is 89.0%\n",
      "Validation Accuracy is 92.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 92.0%\n",
      "Validation Accuracy is 92.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 90.0%\n",
      "Validation Accuracy is 85.0%\n",
      "Accuracy on training data is 96.0%\n",
      "Validation Accuracy is 90.0%\n",
      "Validation Accuracy is 90.0%\n",
      "Validation Accuracy is 91.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Accuracy on training data is 89.0%\n",
      "Validation Accuracy is 91.0%\n",
      "Validation Accuracy is 90.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 91.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 89.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Accuracy on training data is 83.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 92.0%\n",
      "Validation Accuracy is 92.0%\n",
      "Validation Accuracy is 90.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 92.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Accuracy on training data is 92.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 86.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 100.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Accuracy on training data is 98.0%\n",
      "Validation Accuracy is 88.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 92.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 99.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Accuracy on training data is 93.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Accuracy on training data is 93.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 92.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Accuracy on training data is 95.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Accuracy on training data is 94.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 91.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 99.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 92.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 99.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Accuracy on training data is 94.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 99.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Accuracy on training data is 92.0%\n",
      "Validation Accuracy is 99.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 91.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Accuracy on training data is 96.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 99.0%\n",
      "Validation Accuracy is 92.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 92.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Accuracy on training data is 97.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 92.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 92.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Accuracy on training data is 98.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Accuracy on training data is 94.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 99.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Accuracy on training data is 97.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 89.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Accuracy on training data is 94.0%\n",
      "Validation Accuracy is 99.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Accuracy on training data is 96.0%\n",
      "Validation Accuracy is 99.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Accuracy on training data is 93.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 99.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Accuracy on training data is 95.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 100.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Accuracy on training data is 100.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Accuracy on training data is 97.0%\n",
      "Validation Accuracy is 99.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 99.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 99.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Accuracy on training data is 99.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 96.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy is 100.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Accuracy on training data is 97.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 99.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 99.0%\n",
      "Validation Accuracy is 99.0%\n",
      "Accuracy on training data is 96.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 99.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Accuracy on training data is 98.0%\n",
      "Validation Accuracy is 93.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Accuracy on training data is 94.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 99.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Accuracy on training data is 97.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 97.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 96.0%\n",
      "Validation Accuracy is 95.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 98.0%\n",
      "Validation Accuracy is 94.0%\n",
      "Accuracy on training data is 96.0%\n",
      "Validation Accuracy is 98.0%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-75de89015bbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m## 2nd conv layer Backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mdw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_backprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mdh1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m## relu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-203e55eda671>\u001b[0m in \u001b[0;36mconv_backprop\u001b[0;34m(x, dh, layer)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilter_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilter_number\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0msteps_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mtile\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mtile\u001b[0;34m(A, reps)\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdim_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnrep\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m                 \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m//=\u001b[0m \u001b[0mdim_in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LR = 0.0005\n",
    "epochs = 10\n",
    "lr = 0.0001\n",
    "steps = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "\n",
    "    for image_id in range(len(x_train)):\n",
    "        \n",
    "        if steps % 2000 == 0:\n",
    "                # test accuracy\n",
    "                samples = 100\n",
    "                s = 0\n",
    "                for e in range(samples):\n",
    "                    image_id = np.random.randint(len(x_train))\n",
    "                    x = x_train[image_id]\n",
    "                    y_true = y_train[image_id]\n",
    "                    y, good = eval_model(x, y_true)\n",
    "                    if good:\n",
    "                        s += 1\n",
    "                print(\"Accuracy on training data is {}%\".format(100.*s/float(samples)))\n",
    "                accuracy = s/float(samples)\n",
    "        \n",
    "        \n",
    "        if steps % 200 == 0:\n",
    "                # test accuracy\n",
    "                samples = 100\n",
    "                s = 0\n",
    "                for e in range(samples):\n",
    "                    image_id = np.random.randint(len(x_val))\n",
    "                    x = x_val[image_id]\n",
    "                    y_true = y_val[image_id]\n",
    "                    y, good = eval_model(x, y_true)\n",
    "                    if good:\n",
    "                        s += 1\n",
    "                print(\"Validation Accuracy is {}%\".format(100.*s/float(samples)))\n",
    "                accuracy = s/float(samples)\n",
    "                #lr = (1 - accuracy) * LR\n",
    "            \n",
    "        steps += 1\n",
    "        x = x_train[image_id]\n",
    "        y_true = y_train[image_id]\n",
    "\n",
    "        # FORWARD\n",
    "\n",
    "        h1 = conv_forward(x, 0)\n",
    "        h2 = conv_forward(h1, 1)\n",
    "        h2f = h2.flatten()\n",
    "        y3, h3 = dense_forward(h2f, 0)\n",
    "        y, h = dense_forward(y3, 1) \n",
    "\n",
    "        # BACKPROP\n",
    "\n",
    "        ## Loss gradient\n",
    "        grad = categorical_ce_grad(h, y_true)\n",
    "        dy = -grad\n",
    "\n",
    "        ## Dense Backprop\n",
    "\n",
    "        dw3, db3, dh3 = backprop_dense(dy, h3, 1)\n",
    "        dh3[h3<=0.] = 0. ## relu\n",
    "\n",
    "        model['D2'] += lr * dw3\n",
    "        model['b_dense_2'] += lr * db3\n",
    "        \n",
    "        dw2, db2, dh2 = backprop_dense(dh3, h2f, 0)\n",
    "        dh2 = dh2.reshape(h2.shape)\n",
    "        dh2[h2<=0] = 0 ## relu\n",
    "\n",
    "        model['D1'] += lr * dw2\n",
    "        model['b_dense_1'] += lr * db2\n",
    "\n",
    "        ## 2nd conv layer Backprop\n",
    "        dw1, db1, dh1 = conv_backprop(h1, dh2, 1)\n",
    "        dh1[h1<=0] = 0 ## relu\n",
    "\n",
    "        model['F2'] += lr * dw1\n",
    "        model['b_conv_2'] += lr * db1\n",
    "\n",
    "        ## 1st conv layer Backprop\n",
    "        dw0, db0, dx0 = conv_backprop(x.astype('float64'), dh1, 0)\n",
    "\n",
    "        model['F1'] += lr * dw0\n",
    "        model['b_conv_1'] += lr * db0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 97.03%\n"
     ]
    }
   ],
   "source": [
    "samples = 10000\n",
    "s = 0\n",
    "for e in range(samples):\n",
    "    image_id = e\n",
    "    x = x_test[image_id]\n",
    "    y_true = y_test[image_id]\n",
    "    y, good = eval_model(x, y_true)\n",
    "    if good:\n",
    "        s += 1\n",
    "print(\"Accuracy is {}%\".format(100.*s/float(samples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('cnn_model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "#with open('cnn_model.pickle', 'rb') as f:\n",
    "#    m = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
